{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b541090",
   "metadata": {},
   "source": [
    "### Chat Completion API\n",
    "\n",
    "- The simplest way to call an LLM\n",
    "- It's called Chat Completions because it's saying: \"here is a conversation, please predict what should come next\"\n",
    "- The Chat Completions API was invented by OpenAI, but it's so popular that everybody uses it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d05d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71489053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9fd520",
   "metadata": {},
   "source": [
    "Here is the way to setup and called the simplest chat completion API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6686d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'gpt-5-nano',\n",
       " 'messages': [{'role': 'user', 'content': 'Tell me a fun fact'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"gpt-5-nano\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a fun fact\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8969a725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-Ce99EsxYRHt4NOu27OdmjVoxMk6Dk',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1763684320,\n",
       " 'model': 'gpt-5-nano-2025-08-07',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'Honey never spoils. Archaeologists have found pots of edible honey in ancient Egyptian tombs, thousands of years old.',\n",
       "    'refusal': None,\n",
       "    'annotations': []},\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 11,\n",
       "  'completion_tokens': 865,\n",
       "  'total_tokens': 876,\n",
       "  'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n",
       "  'completion_tokens_details': {'reasoning_tokens': 832,\n",
       "   'audio_tokens': 0,\n",
       "   'accepted_prediction_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0}},\n",
       " 'service_tier': 'default',\n",
       " 'system_fingerprint': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the api through requests - using the url/endpoint\n",
    "\n",
    "response = requests.post(\n",
    "    \"https://api.openai.com/v1/chat/completions\",\n",
    "    headers=headers,\n",
    "    json=payload\n",
    ")\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e059548a",
   "metadata": {},
   "source": [
    "OpenAI provides a package to make this API call simpler, it's nothing more than a wrapper around making this exact call to the http endpoint. This makes an API call as simple as calling a function. It just allows you to work with nice Python code instead of messing around with janky json objects. \n",
    "\n",
    "But that's it. It's open-source and lightweight. Some people think it contains OpenAI model code - it doesn't!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a17f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wombats poop cube-shaped feces, a shape that helps it stack and prevents it from rolling away.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create OpenAI client - this behaves similar to the requests library, shown above\n",
    "# But as we can see, it's so easy to use it this way.\n",
    "\n",
    "from openai import OpenAI\n",
    "openai = OpenAI()\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages=[{\"role\": \"user\", \"content\": \"Tell me a fun fact\"}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36db9397",
   "metadata": {},
   "source": [
    "Other Frontier models also provide OpenAI based API call setup.\n",
    "\n",
    "Here is an example for Google's Gemini Model call using OpenAI standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70165ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if not google_api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not google_api_key.startswith(\"AIz\"):\n",
    "    print(\"An API key was found, but it doesn't start AIz\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4333976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The national animal of Scotland is the **unicorn**.\\n\\nIt was chosen in the 15th century because in Celtic mythology, the unicorn symbolized purity, innocence, and power. It was also seen as a symbol of Scottish independence, as it was believed to be the natural enemy of the lion—the symbol of England.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini = OpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)\n",
    "\n",
    "response = gemini.chat.completions.create(model=\"gemini-2.5-pro\", messages=[{\"role\": \"user\", \"content\": \"Tell me a fun fact\"}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f241c38f",
   "metadata": {},
   "source": [
    "### Now we can try Ollama using the same approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54d05d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Ollama is running'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"http://localhost:11434\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d175421",
   "metadata": {},
   "source": [
    "### Download llama3.2 from meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0406a262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbe50894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up ollama to use it using the OpenAI API\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39184abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s another fun fact:\\n\\nDid you know that there is a type of jellyfish that is immortal? The Turritopsis dohrnii, also known as the \"immortal jellyfish,\" is a species of jellyfish that can transform its body into a younger state through a process called transdifferentiation. This means that it can essentially revert back to its polyp stage, which is the juvenile form of a jellyfish, and then grow back into an adult again. This process can be repeated indefinitely, making Turritopsis dohrnii theoretically immortal.\\n\\nIsn\\'t that just amazing?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')\n",
    "\n",
    "response = ollama.chat.completions.create(model=\"llama3.2\", messages=[{\"role\": \"user\", \"content\": \"Tell me another fun fact\"}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e6fa9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling c5ad996bda6e: 100% ▕██████████████████▏  556 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% ▕██████████████████▏  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Now let's try deepseek-r1:1.5b - this is DeepSeek \"distilled\" into Qwen from Alibaba Cloud\n",
    "\n",
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14a31d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Here's another fun fact: **Some animal species predate humans long before they become humans, capable of telling time through body temperature!** For example, newborn babies can detect changes in blood temperature, which they use as a sense of order.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = ollama.chat.completions.create(model=\"deepseek-r1:1.5b\", messages=[{\"role\": \"user\", \"content\": \"Tell me another fun fact\"}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2158c7e5",
   "metadata": {},
   "source": [
    "Building the previously built code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2ea8db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_scraper import fetch_website_contents\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4ee3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Summary**\n",
       "This website belongs to Edward Donner, a snarky AI enthusiast who founded Nebula.io, an AI startup applying machine learning to help people discover their potential. He shares his interests in writing code and experimenting with Large Language Models (LLMs), electronic music production, and Hacker News.\n",
       "\n",
       "**News/Announcements**\n",
       "\n",
       "* Recent posts:\n",
       "\t+ 2025 AI Executive Briefing (November 11, 2025): Donner will be talking about the future of AI.\n",
       "\t+ Be an AI Engineer and Leader: The Curriculum (May 18, 2025): A new course for aspiring engineers and leaders.\n",
       "\t+ AI in Production: Gen AI and Agentic AI on AWS at scale (September 15, 2025): Donner discusses a new project on applying AI technology to production environments.\n",
       "\t+ May 28, 2024 is listed but seems out of date"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a snarky assistant that analyzes the contents of a website,\n",
    "and provides a short, snarky, humorous summary, ignoring text that might be navigation related.\n",
    "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Here are the contents of a website.\n",
    "Provide a short summary of this website.\n",
    "If it includes news or announcements, then summarize these too.\n",
    "\"\"\"\n",
    "\n",
    "website_url = \"https://edwarddonner.com\"\n",
    "\n",
    "contents = fetch_website_contents(website_url)\n",
    "\n",
    "response = ollama.chat.completions.create(model=\"llama3.2\", messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt + \"\\n\\n\" + contents}])\n",
    "\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "839ef675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt + \"\\n\\n\" + website}\n",
    "    ]\n",
    "\n",
    "def summarize_website(website):\n",
    "    website_contents = fetch_website_contents(website)\n",
    "    messages = messages_for(website_contents)\n",
    "    response = ollama.chat.completions.create(model=\"llama3.2\", messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize_website(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee06e490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Meet Ed Donner, a wannabe DJ who's really into AI (not the music)**\n",
       "\n",
       "Ed is a co-founder and CTO of Nebula.io, an AI startup that's all about helping people discover their potential. He's also a fan of amateur electronic music production (ouch) and likes to noodle around with Large Language Models.\n",
       "\n",
       "**News & Announcements**\n",
       "\n",
       "* Ed published a newsletter announcing the \"2025 AI Executive Briefing\", but no actual date or content mentioned.\n",
       "* Recently shared \"AI in Production: Gen AI and Agentic AI on AWS at scale\" from September 2025, likely about his own company's tech.\n",
       "* Earlier still shared info on a May 2025 event called \"Become an AI Engineer and Leader: The Curriculum\", but little more to say."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a3f2153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This website appears to be a news hub for CNN, a 24-hour cable news channel. The most significant content on the homepage includes breaking news, recent news headlines, and videos discussing various global events like the Ukraine-Russia War and the Israel-Hamas War.\n",
       "\n",
       "Some announcements were spotted, including warnings about potential issues with in-stream ads (slowness, freezing, etc.) and calls to submit feedback about these ad experiences.\n",
       " \n",
       " CNN is actively seeking input on its ads' effectiveness, aiming to improve user experience."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0ca657b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# The Ultimate Healthcare Data Enablers\n",
       "\n",
       "It turns out that Health Chain is all about helping healthcare providers and payers \"future proof\" their operations by leveraging clean data. They offer a range of solutions, from interoperability and data management to patient engagement and prior authorization. Their flagship platform uses FHIR APIs and offers features like real-time data processing and data observability.\n",
       "\n",
       "Looks like they've also got some exciting announcements to share:\n",
       "\n",
       "* **Product Release**: Introducing the Hyperion Data Platform for standardizing, analyzing, and transforming healthcare data.\n",
       "* **Webinar Schedule**: Catch their upcoming webinars on topics like FHIR API adoption and data-driven care strategies.\n",
       "* **New eBook**: Download their latest eBook to learn more about \"Unlocking the Power of Healthcare Data\"."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://health-chain.io\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73861de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-eng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
